<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alisa Liu</title>
    <link>https://alisawuffles.github.io/</link>
      <atom:link href="https://alisawuffles.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Alisa Liu</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 09 Nov 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://alisawuffles.github.io/img/icon-32.png</url>
      <title>Alisa Liu</title>
      <link>https://alisawuffles.github.io/</link>
    </image>
    
    <item>
      <title>A guide to Grace Hopper for the rare non-recruiting student</title>
      <link>https://alisawuffles.github.io/post/grace_hopper/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/post/grace_hopper/</guid>
      <description>&lt;p&gt;In the weeks leading up to Grace Hopper this October, I wasn&#39;t sure why I was going. The recruiting opportunities is one of the main pulls of the conference, and seems . There are many who would have loved to take my spot.&lt;/p&gt;

&lt;h3 id=&#34;talks&#34;&gt;Talks&lt;/h3&gt;

&lt;p&gt;On my first day at the conference, I mainly followed the AI track for talks, since this aligned most my research interests. Then I realized that this is really different from an academic conference, where talks present state-of-the-art research. I kept being surprised that the talks here are given by people in industry instead of in academia, where the goal is often building a lucrative product rather than advancing the state of human knowledge or machine capability. But what&#39;s special about Grace Hopper is that their talks span all areas and applications of technology, which isn&#39;t true of an NLP conference or ML conference. I found it much more valuable to view the talks at this conference as a way to learn about topics that I wouldn&#39;t otherwise be exposed to.&lt;/p&gt;

&lt;p&gt;I&#39;ve often been intimidated at academic conferences to ask questions, so asking them here was a really good exercise.&lt;/p&gt;

&lt;h3 id=&#34;university-booths&#34;&gt;University booths&lt;/h3&gt;

&lt;p&gt;Many universities have booths with graduate school admissions officers and current graduate students who will be really excited to hear that you&#39;re interested in their program! It&#39;s an amazing opportunity to get a feel for the school from real people.&lt;/p&gt;

&lt;p&gt;Prepare some questions to ask about the application and what it&#39;s like being a PhD student at their school. Current students are often happy to chat. If you have some copies of your CV on you, you can ask an admissions officer to take a look and judge if you would be a competitive applicant. You can also simply ask, &amp;quot;If I leave a copy of this with you, is there any chance it will make it to someone?&amp;quot; Some took a picture of my CV and emailed it right away to a professor I was interested in, and some wrote the names of professors on the CV for later. Some booths had application fee waivers for those who stopped by to chat.&lt;/p&gt;

&lt;p&gt;I found it really grounding to talk about graduate admissions with people. Speaking my intentions into reality, verbalizing my questions, and receiving feedback on my candidacy helped me feel more comfortable with preparing my application.&lt;/p&gt;

&lt;h3 id=&#34;poster-session&#34;&gt;Poster session&lt;/h3&gt;

&lt;p&gt;There is a nestled-away poster session in the career fair room! It&#39;s super exciting to see other girls presenting their research, and they are all really eager to share their work. Compared to academic conferences, I also found the poster session much more casual and conducive to conversation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Augmentative generation for Bach chorales</title>
      <link>https://alisawuffles.github.io/project/deepbach/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/deepbach/</guid>
      <description>&lt;p&gt;A major limitation of music generation systems for a specific domain is finite training data. Researchers have augmented data with techniques such as transposition, which loses compositional information specific to its original key, or by extracting multiple short segments from each piece, which loses long-term coherence. We propose an alternative method which augments a dataset limited in training examples by using an existing model’s generated output weighted by a hand-crafted score function, to feed back as new training data to update the model. We try this method with DeepBach, a model trained to generate chorales in the style of Bach, a task where gold data is inherently limited to the 389 chorales Bach wrote in his lifetime. While this is a large output for a single composer, it is not enough for training deep models. Our hypothesis is that training on high-quality generated output is more useful than training on simple transformations of the same music.&lt;/p&gt;

&lt;p&gt;This is very much a work in progress and we hope to use our class project as an opportunity to be extra creative, so please let us know if you have any thoughts or suggestions!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Definition modeling for noun compounds</title>
      <link>https://alisawuffles.github.io/project/noun-compounds/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/noun-compounds/</guid>
      <description>&lt;p&gt;Developing a neural language model that generates definitions and paraphrases of noun compounds (e.g. “caramel popcorn”). We identified a large pool of noun compounds in text using a POS-tagging rule, and we are currently incorporating human-authored definitions for these unlabeled noun compounds to evaluate the impact of active learning on generation tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ensemble model for audio source separation</title>
      <link>https://alisawuffles.github.io/project/ensemble/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/ensemble/</guid>
      <description>&lt;p&gt;Built an ensemble model for audio source separation that can handle mixtures whose source domain is unknown, using a confidence measure to mediate among domain-specific models based on deep clustering. We derived a confidence measure based on the clusterability of the embedding space which approximates the separation quality without ground-truth comparison.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Model Selection for Deep Audio Source Separation via Clustering Analysis</title>
      <link>https://alisawuffles.github.io/publication/ensemble/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/publication/ensemble/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-sense Definition Modeling using Word Sense Decompositions</title>
      <link>https://alisawuffles.github.io/publication/multidef/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/publication/multidef/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CODAH: An Adversarially Authored Question-Answer Dataset for Common Sense</title>
      <link>https://alisawuffles.github.io/publication/codah/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/publication/codah/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Common sense QA dataset</title>
      <link>https://alisawuffles.github.io/project/codah/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/codah/</guid>
      <description>&lt;p&gt;Produced an adversarially generated commonsense question-answer dataset, using a novel question acquisition procedure where workers author questions designed to target weaknesses of state-of-the-art neural QA systems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysis of error types in multi-sense definition generation</title>
      <link>https://alisawuffles.github.io/project/multidef/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/multidef/</guid>
      <description>&lt;p&gt;Evaluated the settings under which a multi-sense definition modeling system succeeded and failed by investigating whether certain attributes of words and atoms were predictive of model performance. Used logistic regression with these attributes (e.g. word frequency, embedding norm, part of speech) to predict individual error types as well as a manual evaluation score. We found that atom weight was a significant predictor for score, showing that atoms with greater weights are likely to represent more dominant sense that are easier to define.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Comparison of Discourse Surrounding CRISPR/Cas9 in the Media and Peer-Reviewed Literature</title>
      <link>https://alisawuffles.github.io/publication/crispr/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/publication/crispr/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
