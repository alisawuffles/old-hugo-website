<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nlp | Alisa Liu</title>
    <link>https://alisawuffles.github.io/tags/nlp/</link>
      <atom:link href="https://alisawuffles.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <description>nlp</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 01 Nov 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://alisawuffles.github.io/img/icon-32.png</url>
      <title>nlp</title>
      <link>https://alisawuffles.github.io/tags/nlp/</link>
    </image>
    
    <item>
      <title>Definition modeling for noun compounds</title>
      <link>https://alisawuffles.github.io/project/noun-compounds/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/noun-compounds/</guid>
      <description>&lt;p&gt;Developing a neural language model that generates definitions and paraphrases of noun compounds (e.g. “caramel popcorn”). We identified a large pool of noun compounds in text using a POS-tagging rule, and we are currently incorporating human-authored definitions for these unlabeled noun compounds to evaluate the impact of active learning on generation tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Common sense QA dataset</title>
      <link>https://alisawuffles.github.io/project/codah/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/codah/</guid>
      <description>&lt;p&gt;Produced an adversarially generated commonsense question-answer dataset, using a novel question acquisition procedure where workers author questions designed to target weaknesses of state-of-the-art neural QA systems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysis of error types in multi-sense definition generation</title>
      <link>https://alisawuffles.github.io/project/multidef/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://alisawuffles.github.io/project/multidef/</guid>
      <description>

&lt;p&gt;Word embeddings capture syntactic and semantic information about words. Definition modeling aims to make the semantic content in each embedding explicit, by outputting a natural language definition based on the embedding. However, existing definition models are limited in their ability to generate accurate definitions for different senses of the same word. In this paper, we introduce a new method that enables definition modeling for multiple senses. Some selected examples are shown below.&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../../img/multidef_ex.png&#34; data-caption=&#34;Selected examples of the multi-sense definition model&amp;rsquo;s outputs&#34;&gt;
&lt;img src=&#34;../../img/multidef_ex.png&#34; alt=&#34;&#34; width=&#34;50%&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Selected examples of the multi-sense definition model&amp;rsquo;s outputs
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;h2 id=&#34;quantitative-analysis-of-error-types&#34;&gt;Quantitative analysis of error types&lt;/h2&gt;

&lt;p&gt;In my project, my goal was to better understand the settings under which our best model (W2MDEF-GS) succeeds and failed.&lt;/p&gt;

&lt;p&gt;To evaluate the generated definitions, we manually label outputs as one of four categories: ${\bf I}$ the output is correct; ${\bf II}$ the output has &lt;em&gt;either&lt;/em&gt; a syntax/fluency error or a semantic issue, but not both; ${\bf III}$ the output has both a syntactic and semantic error but is not completely wrong; and ${\bf IV}$ where the output is completely wrong. When evaluating precision and recall, the four labeling categories are given scores $1.0$, $0.6$, $0.3$, and $0.0$ respectively.  A breakdown of the error types is shown below.&lt;/p&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../../img/multidef_error_types.png&#34; data-caption=&#34;A breakdown of error types, and the percentage of each in our best model vs. the baseline. For each error type, one example is provided. An output can have more than one error type.&#34;&gt;
&lt;img src=&#34;../../img/multidef_error_types.png&#34; alt=&#34;&#34; width=&#34;50%&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    A breakdown of error types, and the percentage of each in our best model vs. the baseline. For each error type, one example is provided. An output can have more than one error type.
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;p&gt;I investigated whether certain attributes of words and atoms are predictive of model performance. The word attributes we considered included the ranking of word frequency, the number of ground-truth definitions of the word, the semantic diversity of ground-truth definitions, and the word embedding norm.  Atom attributes included the atom weight after decomposition and the part of speech of the atom. We used logistic regression with these attributes to predict two different output variables: individual error types and the score from $0$ to $1$. For predicting the score, we trained logistic regression to minimize the cross-entropy between the model output and the score (i.e., we treated the non-0/1 score labels as probabilities). We performed 5-fold validation, where atoms belonging to the same word must always be in the same fold.&lt;/p&gt;

&lt;p&gt;I was unable to predict the individual error labels with accuracy above baseline, which suggests the attributes were not good predictors given the scale of data we had available, and demonstrates that definition generation is still a challenging problem. However, the score prediction model predicts the score with $0.48$ loss, compared to the $0.53$ baseline, using only atom weight as an attribute, which is a significant predictor with p-value $&amp;lt; 0.01$. We hypothesize that this is because atoms with greater weight are more likely to represent more dominant senses that are easier to define.  In fact, the atoms with the top 10\% in weight have an average score of $0.35$, substantially higher than the average score of $0.19$ across all atoms.&lt;/p&gt;

&lt;p&gt;In a separate analysis of part of speech, I found that adjectives achieve the highest average score. This is likely the result of having the shortest average output definition length, making the redundancy label (the most common syntactical failure mode) rare. (Adjectives have the redundancy label $3\%$ of the time, compared to $15\%$ for nouns.)&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;POS&lt;/th&gt;
&lt;th&gt;average score&lt;/th&gt;
&lt;th&gt;average length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;adj&lt;/td&gt;
&lt;td&gt;0.39&lt;/td&gt;
&lt;td&gt;5.7&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;noun&lt;/td&gt;
&lt;td&gt;0.30&lt;/td&gt;
&lt;td&gt;10.1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;adv&lt;/td&gt;
&lt;td&gt;0.32&lt;/td&gt;
&lt;td&gt;7.2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;verb&lt;/td&gt;
&lt;td&gt;0.31&lt;/td&gt;
&lt;td&gt;5.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>
